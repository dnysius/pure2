{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setpinski [19], wavenumber algorithm [16], [17]\n",
    "\n",
    "1. Split the data pre focal region and post focal region\n",
    "\n",
    "2. Prefocal consists of electro-mechanical impulse response and excitation pulse ($s_\\text{pre}(x_n,t)$ and $h_\\text{pre}(t)$) is reversed in axial direction\n",
    "\n",
    "3. 2D FFT on all data to get $S(k_x, \\omega), H(\\omega), P(\\omega)$. Far field directivity pattern of VS is assumed to be $A=jinc^2(k_xa)$ , where $a$ is radius of the flat circular virtual source that can be determined from the simulated beam profile.\n",
    "\n",
    "(see: \n",
    "\n",
    "https://en.wikipedia.org/wiki/Sombrero_function, \n",
    "\n",
    "https://en.wikipedia.org/wiki/Bessel_function#Bessel_functions_of_the_first_kind:_J%CE%B1, \n",
    "\n",
    "https://www.johndcook.com/blog/2012/02/02/how-to-compute-jincx/)\n",
    "\n",
    "4. Image reconstruction\n",
    "$$F(k_x, k_z)=\\mathcal{S}\\left\\{\\exp\\left[j(\\sqrt{4k^2-k_x^2}-2k)z_c\\right]A^*\\omega^2H^*(\\omega)P^*(\\omega)S(k_x,\\omega)\\right\\}$$\n",
    "\n",
    "where $\\mathcal{S}\\{\\cdot\\}$ is the Stolt transformation. $z_c$ is the perpendicular distance from the transducer to the midpoint of the ROI. $k=\\omega/c$. \n",
    "\n",
    "Stolt migration:\n",
    "\n",
    "http://sepwww.stanford.edu/sep/prof/iei/omk/paper_html/node11.html\n",
    "\n",
    "https://www.math.ucdavis.edu/~saito/data/sonar/stolt.pdf\n",
    "\n",
    "5. 2D IFFT on $F_\\text{pre}$ and $F_\\text{post}$ to spatial domain, $F_\\text{pre}$ flipped axially, and then stitched together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-SAFT\n",
    "\n",
    "Image reconstruction is done by delaying the recorded echo signals according to the relative positions of the image pixel and the transducer, which is then followed by a coherent summation. Each point $(x,z)$ in the image is brought into focus by applying appropriate time-delays to the recorded echo data $s(x_n,t)$ for all the transducer positions $x_n(n\\in\\{0\\ldots L-1\\})$ in the synthetic aperture and then performing summation as follows,\n",
    "$$f_\\text{TD}(x,z)=\\sum_{n=0}^{L-1}s\\left(x_n, \\dfrac{2}{c_0}\\sqrt{(x-x_n)^2+z^2}\\right)$$\n",
    "\n",
    "where $c_0$ is the speed of sound, and $f_\\text{TD}(x,z)$ is the reconstructed TD-SAFT image.\n",
    "\n",
    "The time-domain virtual point source SAFT (TD-SAFT-VPS), treats the focus of the transducer as a point source where the above equation is applied in the pre-focal and post-focal regions separately. In the pre-focal region, the recorded echo data is flipped in the axial direction and then DAS is applied. In the post-focal region, DAS is applied to the recorded echo data without changing the orientation of the data. After applying DAS, the pre-focal region is flipped back to its original orientation before joining it with the post-focal region. **In addition, the image intensity of each point can be normalized by dividing the square root of the number of scanlines used at each point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import \\\n",
    "    reshape as np_reshape, \\\n",
    "    power as np_power, \\\n",
    "    sqrt as np_sqrt, \\\n",
    "    argmin as np_argmin, \\\n",
    "    abs as np_abs, \\\n",
    "    sum as np_sum\n",
    "from os import getcwd\n",
    "from os.path import join, dirname\n",
    "import pickle\n",
    "from time import clock\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "global min_step, c_0, DEFAULT_ARR_FOLDER\n",
    "global xarr, FD, SD, pbar, T, V, L, T_COMPARE, PRE_OUT, POST_OUT, xni\n",
    "FOLDER_NAME = \"1D-15FOC3in\"\n",
    "#DEFAULT_ARR_FOLDER = join(dirname(getcwd()), \"data\", FOLDER_NAME)\n",
    "DEFAULT_ARR_FOLDER = getcwd()\n",
    "FOCAL_DEPTH = 0.0381  # 1.5 inch in metres\n",
    "SAMPLE_DEPTH = 15000\n",
    "min_step = 4e-4\n",
    "c_0 = 1498  # water\n",
    "\n",
    "\n",
    "def load_arr(output_folder=DEFAULT_ARR_FOLDER):\n",
    "    ftarr = join(output_folder, \"tarr.pkl\")\n",
    "    fvarr = join(output_folder, \"varr.pkl\")\n",
    "    with open(ftarr, 'rb') as rd:\n",
    "        tarr = pickle.load(rd)\n",
    "    with open(fvarr, 'rb') as rd:\n",
    "        varr = pickle.load(rd)\n",
    "    return tarr, varr\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array, dtype=float)\n",
    "    return (np.abs(array - value)).argmin()\n",
    "\n",
    "\n",
    "def SAFT(xi):\n",
    "    x = xarr[xi]\n",
    "    ti = 0\n",
    "    while ti < SD:\n",
    "        if ti < FD:  # PRE\n",
    "            z = T[ti]*c_0/2\n",
    "            ind = np_reshape((2/c_0)*np_sqrt(np_power(x-xarr[xni], 2)\n",
    "                             + np_power(z, 2)), (L, 1))\n",
    "            zi = np_argmin(np_abs(T_COMPARE - ind), axis=1)\n",
    "            PRE_OUT[ti, xi] = np_sum(V[zi, xi])\n",
    "        elif ti >= FD:  # POST\n",
    "            z = T[ti]*c_0/2\n",
    "            ind = np_reshape((2/c_0)*np_sqrt(np_power(x-xarr[xni], 2)\n",
    "                             + np_power(z, 2)), (L, 1))\n",
    "            zi = np_argmin(np_abs(T_COMPARE - ind), axis=1)\n",
    "            POST_OUT[ti-FD, xi] = np_sum(V[zi, xi])\n",
    "        ti += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = clock()\n",
    "    tarr, varr = load_arr()\n",
    "    tarr = tarr[:, 0, :]\n",
    "    varr = varr[:, 0, :]\n",
    "    ZERO = find_nearest(tarr[:, 0], 0)\n",
    "    T = tarr[ZERO:, 0]  # 1D, time columns all the same\n",
    "    V = varr[ZERO:, :]  # 2D\n",
    "    FD = find_nearest(T, 2*FOCAL_DEPTH/c_0)  # focal depth\n",
    "    # SD = find_nearest(T, 2*SAMPLE_DEPTH/c_0) + 1  # sample depth\n",
    "    SD = len(T)-1\n",
    "    L = np.shape(V)[1]\n",
    "    T_COMPARE = np.empty((L, len(T)))\n",
    "    for l in range(L):\n",
    "        T_COMPARE[l, :] = T[:]\n",
    "    xarr = np.linspace(-L/2, L/2, L)*min_step\n",
    "    PRE = np.flip(V[:FD, :], axis=0)\n",
    "    PRE_T = np.flip(T[:FD], axis=0)\n",
    "    PRE_OUT = np.empty(np.shape(PRE))\n",
    "    POST = V[FD:SD, :]\n",
    "    POST_T = T[FD:SD]\n",
    "    POST_OUT = np.empty(np.shape(POST))\n",
    "    xni = np.arange(0, L, 1)\n",
    "\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    results = pool.map(SAFT, [l for l in range(L)])\n",
    "    pool.close()\n",
    "\n",
    "    PRE_OUT = np.flip(PRE_OUT, axis=0)\n",
    "    STITCHED = np.vstack((PRE_OUT, POST_OUT))\n",
    "    pickle.dump(STITCHED, open(join(getcwd(),\"{}-test.pkl\".format(FOLDER_NAME)), \"wb\"))\n",
    "    print('total time: {}'.format(clock()-start))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
